{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download de dados\n",
        "Esse notebook foi utilizado para possibilitar que todos os membros do grupo fizessem o download dos dados do banco Firebase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcwqWPS10AOg"
      },
      "source": [
        "## Funções Auxiliares\n",
        "Import de biliotecas e definição de funções usadas para acessar o banco de dados e converter as informações obtidas em vetores numpy compatíveis com a biblioteca Skit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "UTjfL6cDYSIU",
        "outputId": "63652173-ebac-4693-9395-e275e2362ea8"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import firebase_admin\n",
        "import json\n",
        "import numpy as np\n",
        "from firebase_admin import credentials, firestore\n",
        "\n",
        "cred = credentials.Certificate(\"/content/serviceAccountKey.json\")\n",
        "firebase_admin.initialize_app(cred)\n",
        "\n",
        "db = firestore.client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0vk6j8JwzOd"
      },
      "outputs": [],
      "source": [
        "def translate_y(y, inv=False):\n",
        "  \"\"\"\n",
        "  O vetor de respostas sai do banco de dados como uma lista de caracteres,\n",
        "  para possibilitar maior modularização na programação. Essa função traduz\n",
        "  o vetor de respostas para um vetor de inteiros (para torná-la compatível\n",
        "  com o modelo) e vice-versa (para traduzir a resposta do modelo).\n",
        "  \"\"\"\n",
        "  result = []\n",
        "  translate = {\n",
        "    'a': 0,\n",
        "    'b': 1,\n",
        "    'c': 2,\n",
        "    'd': 3,\n",
        "    'e': 4,\n",
        "    'f': 5,\n",
        "    'g': 6,\n",
        "    'h': 7,\n",
        "    'i': 8,\n",
        "    'j': 9,\n",
        "    'k': 10,\n",
        "    'l': 11,\n",
        "    'm': 12,\n",
        "    'n': 13,\n",
        "    'o': 14,\n",
        "    'p': 15,\n",
        "    'q': 16,\n",
        "    'r': 17,\n",
        "    's': 18,\n",
        "    't': 19,\n",
        "    'u': 20,\n",
        "    'v': 21,\n",
        "    'w': 22,\n",
        "    'x': 23,\n",
        "    'y': 24,\n",
        "    'z': 25,\n",
        "  }\n",
        "  translate_inv = {}\n",
        "  for value in translate:\n",
        "    translate_inv[str(translate[value])] = value\n",
        "  \n",
        "  if inv:\n",
        "    return translate_inv[str(y)]\n",
        "\n",
        "  for elem in y:\n",
        "    if elem in translate:\n",
        "      result.append(translate[elem])\n",
        "    else:\n",
        "      result.append(elem)\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-a1NqjWYxj2"
      },
      "outputs": [],
      "source": [
        "def import_data():\n",
        "  \"\"\"\n",
        "  Importa os dados do banco de dados e retorna um vetor de vetores de\n",
        "  posicionamento das features das mãos e um vetor de respostas dizendo\n",
        "  qual letra o sinal manual representa.\n",
        "  \"\"\"\n",
        "  docs = db.collection(\"X\").stream()\n",
        "\n",
        "  y = []\n",
        "  X = []\n",
        "  for doc in docs:\n",
        "    X_amostra = doc.to_dict()\n",
        "    y_doc = db.collection(\"y\").document(doc.id).get()\n",
        "    if not y_doc.exists:\n",
        "      continue\n",
        "    y_amostra = y_doc.to_dict()\n",
        "\n",
        "    y_amostra = y_amostra['value']\n",
        "    X_amostra = X_amostra['value']\n",
        "\n",
        "    y+=y_amostra\n",
        "    X+=X_amostra\n",
        "\n",
        "  y = translate_y(y)\n",
        "  y = np.array(y).flatten()\n",
        "  y = y.astype(int)\n",
        "  X = np.array(X).reshape(-1, 63)\n",
        "\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXqqnP4Tc18l"
      },
      "outputs": [],
      "source": [
        "def import_data_untranslated():\n",
        "  \"\"\"\n",
        "  Similar a import_data, porém aqui a saída y é retornada\n",
        "  como um array de strings. Útil para caso se queira trabalhar\n",
        "  com um subset do alfabeto enviado para o banco (tal qual\n",
        "  decidimos fazer no projeto).\n",
        "  \"\"\"\n",
        "  docs = db.collection(\"X\").stream()\n",
        "\n",
        "  y = []\n",
        "  X = []\n",
        "  for doc in docs:\n",
        "    X_amostra = doc.to_dict()\n",
        "    y_doc = db.collection(\"y\").document(doc.id).get()\n",
        "    if not y_doc.exists:\n",
        "      continue\n",
        "    y_amostra = y_doc.to_dict()\n",
        "\n",
        "    y_amostra = y_amostra['value']\n",
        "    X_amostra = X_amostra['value']\n",
        "\n",
        "    y+=y_amostra\n",
        "    X+=X_amostra\n",
        "\n",
        "  X = np.array(X).reshape(-1, 63)\n",
        "\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJLQtYR06Vp"
      },
      "source": [
        "## Baixa os dados\n",
        "Baixa os dados completos do banco de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpja2AOuqxHv"
      },
      "outputs": [],
      "source": [
        "X, y = import_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BaC3tdMdCNb"
      },
      "source": [
        "## Testando com alfabetos diferentes\n",
        "Aqui utilizamos a função de `import_data_unstranlated()` para testar com um subset de letras mais destacadas entre si. Por exemplo, como as letras \"f\" e \"t\" são extramamente similares, escolhemos manter apenas a letra mais popular no português - t - e descartar a outra. Dessa forma, pudemos garantir uma eficácia maior para o nosso modelo preditivo com o número limitado de dados que obtivemos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab8yMA1sdFmr"
      },
      "outputs": [],
      "source": [
        "X_unt, y_unt = import_data_untranslated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txAQG9msdRDJ"
      },
      "outputs": [],
      "source": [
        "def filter_alphabet(X_unt, y_unt, selected_alphabet):\n",
        "  X = []\n",
        "  y = []\n",
        "  for i, letter in enumerate(y_unt):\n",
        "    if letter in selected_alphabet:\n",
        "      y.append(y_unt[i])\n",
        "      X.append(X_unt[i])\n",
        "\n",
        "  # converte y para sktlearn novamente\n",
        "  y = translate_y(y)\n",
        "  y = np.array(y).flatten()\n",
        "  y = y.astype(int)\n",
        "\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuo2hYcTfhPA"
      },
      "outputs": [],
      "source": [
        "selected_alphabet = ['a', 'o', 'e', 'r', 'n', 'd', 't', 'l', 'p', 'v', 'g', 'b', 'q']\n",
        "\n",
        "X, y = filter_alphabet(X_unt, y_unt, selected_alphabet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ2QgRhP9ZYI"
      },
      "source": [
        "## Salva os dados em arquivos baixáveis\n",
        "Salva os dados para serem baixados e acessados no notebook de teste de eficiência de modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWWtgbzbAehG"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('X.data', 'wb') as f:\n",
        "  pickle.dump(X, f)\n",
        "with open('y.data', 'wb') as f:\n",
        "  pickle.dump(y, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xcwqWPS10AOg",
        "PCTFxzVF1JxD",
        "7n6LIFcY3dn2",
        "-nJLQtYR06Vp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "eef08866a9898f3d66d483d958c7ee235777df3178bcc948efcc758beb88e60b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
