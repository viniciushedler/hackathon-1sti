{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de Modelos\n",
    "Nesse notebook nós testamos diferentes modelos de classificação do skit-learn para descobrir qual a melhor técnica para predição dos sinais em libras feitos pelo usuário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções Auxiliares\n",
    "Import de bibliotecas e definição de funções para a importação de dados e testes de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa os dados do pickle\n",
    "X = pickle.load(open(\"X_selected_alphabet.data\", \"rb\"))\n",
    "y = pickle.load(open(\"y_selected_alphabet.data\", \"rb\"))\n",
    "alphabet = pickle.load(open(\"alphabet-laguardia.data\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_y(y, inv=False):\n",
    "  result = []\n",
    "  translate = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    'e': 4,\n",
    "    'f': 5,\n",
    "    'g': 6,\n",
    "    'h': 7,\n",
    "    'i': 8,\n",
    "    'j': 9,\n",
    "    'k': 10,\n",
    "    'l': 11,\n",
    "    'm': 12,\n",
    "    'n': 13,\n",
    "    'o': 14,\n",
    "    'p': 15,\n",
    "    'q': 16,\n",
    "    'r': 17,\n",
    "    's': 18,\n",
    "    't': 19,\n",
    "    'u': 20,\n",
    "    'v': 21,\n",
    "    'w': 22,\n",
    "    'x': 23,\n",
    "    'y': 24,\n",
    "    'z': 25,\n",
    "  }\n",
    "  translate_inv = {}\n",
    "  for value in translate:\n",
    "    translate_inv[str(translate[value])] = value\n",
    "  \n",
    "  if inv:\n",
    "    return translate_inv[str(y)]\n",
    "\n",
    "  for elem in y:\n",
    "    if elem in translate:\n",
    "      result.append(translate[elem])\n",
    "    else:\n",
    "      result.append(elem)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_alphabet(input):\n",
    "    matches = 0\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'i', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v']\n",
    "    alphabet = ['a', 'o', 'e', 'r', 'n', 'd', 't', 'l', 'p', 'v', 'g', 'b', 'q']\n",
    "    alphabet = ['a', 'b', 'd', 'e', 'g', 'l', 'n', 'o', 'p', 'q', 'r', 't', 'v']\n",
    "    \n",
    "    for i, letter in enumerate(alphabet):\n",
    "        if letter == input[i]:\n",
    "            matches += 1\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtra o vetor de testes `alhpabet` com apenas as letras inclusas no alfabeto selecionado\n",
    "selected_alphabet = ['a', 'o', 'e', 'r', 'n', 'd', 't', 'l', 'p', 'v', 'g', 'b', 'q']\n",
    "old_alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'i', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v']\n",
    "\n",
    "new_alphabet = []\n",
    "for i, letter in enumerate(old_alphabet):\n",
    "    if letter in selected_alphabet:\n",
    "        new_alphabet.append(alphabet[i])\n",
    "new_alphabet = np.array(new_alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de Modelos\n",
    "Testa uma gama de modelos de classificação do Skit-learn para descobrirmos quais trazem os melhores resultados de predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports a range of classifier models from sktlearn\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# creates a list of tuples containing the classifier models and their names\n",
    "classifiers = [\n",
    "    (\"Decision Tree\", tree.DecisionTreeClassifier()),\n",
    "    (\"Random Forest\", RandomForestClassifier()),\n",
    "    (\"K Nearest Neighbors\", KNeighborsClassifier(1)),\n",
    "    (\"Gaussian Naive Bayes\", GaussianNB()),\n",
    "    (\"Support Vector Machine\", SVC()),\n",
    "    (\"Logistic Regression\", LogisticRegression()),\n",
    "    (\"Multi-Layer Perceptron\", MLPClassifier()),\n",
    "]\n",
    "\n",
    "# for each classifier in the list of tuples, fit the model to the training data\n",
    "for name, clf in classifiers:\n",
    "    clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree \t\t answers: ['a', 't', 'd', 'l', 'g', 'l', 'd', 'e', 'q', 'q', 'r', 'b', 'r'] \t\t matches: 6\n",
      "Random Forest \t\t answers: ['a', 't', 'd', 'e', 'g', 'l', 'q', 'e', 'a', 'q', 'r', 't', 'r'] \t\t matches: 8\n",
      "K Nearest Neighbors \t\t answers: ['a', 't', 'd', 'b', 'g', 'l', 'q', 'o', 'd', 'q', 'r', 'd', 'r'] \t\t matches: 7\n",
      "Gaussian Naive Bayes \t\t answers: ['a', 't', 'd', 'b', 'l', 'l', 'q', 't', 'b', 'q', 'r', 't', 'r'] \t\t matches: 6\n",
      "Support Vector Machine \t\t answers: ['a', 't', 'd', 'e', 'l', 'l', 'q', 'o', 'd', 'q', 'r', 'b', 'r'] \t\t matches: 7\n",
      "Logistic Regression \t\t answers: ['a', 'b', 'd', 'e', 'l', 'l', 'q', 'o', 'l', 'q', 'r', 't', 'v'] \t\t matches: 10\n",
      "Multi-Layer Perceptron \t\t answers: ['a', 'b', 'd', 'e', 'g', 'l', 'q', 'o', 'p', 'q', 'r', 't', 'v'] \t\t matches: 12\n"
     ]
    }
   ],
   "source": [
    "for name, clf in classifiers:\n",
    "    answers = []\n",
    "    for letter in new_alphabet:\n",
    "        answers.append(translate_y(\n",
    "            clf.predict(letter.reshape(1, -1))[0], inv=True))\n",
    "    \n",
    "    print(f\"{name} \\t\\t answers: {answers} \\t\\t matches: {matches_alphabet(answers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria e exporta o melhor modelo\n",
    "Baseado nos testes anteriores, descobrimos quais seriam os modelos com melhores resultados: KNN, Perceptron e Linear Regression. Baseado nos testes em outro notebook, descobrimos qual seria a melhor combinação modelo - hiper-parâmetro para a predição de resultados. A partir disso, concluímos que o Logistic Regression com os hiper-parâmetros abaixo faz as melhores predições.\n",
    "Nessa célula, criamos e treinamos o modelo e o exportamos através do Pickle, para utilizar no produto final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(\n",
    "    penalty='none',\n",
    "    fit_intercept=False,\n",
    "    class_weight='balanced',\n",
    "    max_iter=100,\n",
    "    solver='newton-cg',\n",
    "    multi_class='ovr',\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# testa o resultado para a letra a\n",
    "model.predict(new_alphabet[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporta o modelo para o arquivo\n",
    "pickle.dump(model, open(\"model.data\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eef08866a9898f3d66d483d958c7ee235777df3178bcc948efcc758beb88e60b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
